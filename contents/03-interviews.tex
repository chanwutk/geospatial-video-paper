% !TEX root =  ../geospatial-video.tex

\section{Interviews}

\todo{What research questions drove the design of the study?}
In our user interviews, we 

\todo{How did you collect data about your target population?}

\todo{How did you find participants?}

\todo{How did you select participants?}

\todo{What procedure did you use for collecting data?}

\todo{What materials, if any, did you show participants?}

\todo{What data did you collect?}




\todo{What did you learn from the user data?}

\todo{How did you learn it?  What led you to these conclusions?  Be specific.}

\todo{What quotes, stories, numbers, or patterns back up these conclusions or offer extra detail?}

\todo{Which conclusions surprised you?}

\todo{How did your conclusions from the user data affect what you did next?}

\todo{How should your conclusions from the user data affect what future researchers do?}

\todo{andrew?}


In order to identify short-comings for current tools and guide the design of our work, we conducted contextual inquiry and observed users performing tasks involving geospatial video analysis using existing tools. An area of the pipeline which we were especially interested in is how researchers specify queries that identify situations with multiple objects, potentially with some specific behavior over time. The following section discusses the findings from our two interviews in greater detail.

% Who are your formative study participants?
% Lisa Pickoff-White: KQED
% Investigating videos for police misconduct cases
% Yousef Helal: Undergraduate students at Berkeley
% Working on translating query from Scenic to Apperception query
% What protocol are you using during sessions with participants?
% Lisa
% Contextual Inquiry
% Yousef
% Contextual Inquiry
% Structured questions asking participant to rank choices
% Explanation: With multiple tasks, we will give him 2 queries for each task written with the old Apperception API and our new API. Then, we find Yousef's preferences for each task.
% What activities are your participants completing?
% Lisa
% We asked her to prepare a video investigating task.
% We also asked her to choose the task that takes about 20-30 minutes.
% Then, we will observe her workflow for the task.
% We might raise questions if we need any clarification.
% Yousef
% We asked him to prepare a query from Scenic to translate into an Apperception query.
% We can have 1-2 queries and would take around 5-10 minutes.
% We also will ask him to bring a Scenic query that is difficult to write in Apperception.
% Show him our new design and how it works.
% Give multiple queries in our new design
% Ask him to give a short description of each of the queries.
% What data are you collecting?
% Lisa
% Screen recording (need their permission)
% Workflow for her video data exploration. Which parts are slow?
% Yousef
% Screen recording (need their permission)
% The query that he decides to write in Apperception.
% What are the questions that Apperception cannot describe?
% Comparing the API from Apperception and ours
% The confidence level that they will be able to answer their question with our new API.
% How are you going to analyze that data?
% Record their pain points during the interviews. Afterward, we try to group them into larger concepts
% Take general notes on parts of the analysis process that cause the study participants to pause, as these may be aspects of the query creation process that we can optimize
% For Yousef, the API examples we provide will be categorized ahead of time into the types of constructs (functional, declarative, etc.) that they use; we will then attempt to identify how these constructs affected the confidence scores




\subsection{Data Journalist}
User L is a data journalist at a public radio station who must look at video evidence on the order of thousandsto collect and report on evidence, specifically surrounding police misconduct. With permission, we recorded L performing the video queries required for this task. In L's workflow, she goes through several videos and makes quick notes on their utility for her aim; for relevant videos, she ``clicks around a little" through frames to roughly orient herself with what is happening in the scene. Once key frames are identified, L takes 



\todo{focus on why we need to filter by frame instead of just filtering by objects like in apperception}
\todo{to scope down the part of each video that are as of useful to them}

\subsection{Programmer}
\todo{focus on our syntax and data model that it is understandable}
\todo{focus on the part where he suggests us to implement a syntax where users can filter by frame and then switch to filter by objects}