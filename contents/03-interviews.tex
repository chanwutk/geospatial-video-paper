% !TEX root =  ../geospatial-video.tex

\section{Interviews}

In order to identify short-comings for current tools and guide the design of our work, we conducted contextual inquiry and observed users performing tasks involving geospatial video analysis using existing tools. An area of the pipeline which we were especially interested in is how researchers specify queries that identify situations with multiple objects, potentially with some specific behavior over time. The following section discusses the findings from our two interviews in greater detail.

% We asked him to prepare a query from Scenic to translate into an Apperception query.
% We can have 1-2 queries and would take around 5-10 minutes.
% We also will ask him to bring a Scenic query that is difficult to write in Apperception.
% Show him our new design and how it works.
% Give multiple queries in our new design
% Ask him to give a short description of each of the queries.

% The query that he decides to write in Apperception.
% What are the questions that Apperception cannot describe?
% Comparing the API from Apperception and ours
% The confidence level that they will be able to answer their question with our new API.


% For Yousef, the API examples we provide will be categorized ahead of time into the types of constructs (functional, declarative, etc.) that they use; we will then attempt to identify how these constructs affected the confidence scores




\subsection{Data Journalism}
User L is a data journalist at a public radio station who must look at video evidence on the order of thousands to collect and report on evidence, specifically surrounding police misconduct. With permission, we recorded L performing the video queries required for this task. In L's workflow, L goes through several videos and makes quick notes on how they relate to each other and which ones might be most helpful, and clicks through frames to roughly gauge what is happening in the video. She logs information about each video and key frames, consisting of information such as the subjects and objects present in the video and what is happening.

This user study illustrated two key needs. One is the need for users to be able to have as much metadata as possible about videos and frames in order to save time; much of the pipeline involves scoping down parts of the video until the relevant segments and frames are found. Second, we observe the level of detail within frames that is needed (e.g. ``This car is moving towards the officer, that's very important") for key frames, as well as the level of context needed before an inference can be made on what has happened. This indicates that simplifying how users access and query the video annotations and metadata alleviates bottle-necks in the workflow. In our language, the data model are designed to address this (see Section \ref{})



% \todo{focus on why we need to filter by frame instead of just filtering by objects like in apperception}
% \todo{to scope down the part of each video that are as of useful to them}

\subsection{Programmer}

User Y is a student researcher who translates between Scenic to Apperception queries to aid in geospatial research. The task we observe is to find all frames with a specific instance -- in this case, to find all frames with a car.
....

We give Y an intuitive description of what the queries in our language aim to do by looking at the syntax alone, after a short short overview of the key elements of our language. The tasks are to: (1) identify all frames where more than two cars are present; (2) Identify all instances which has another instance moving towards them; (3) Identify instances of people where they are moving away from a car ; and (4) Identify all cars to the left of the camera. These reflect calls which may be neccesary for a researcher building planning or machine learning models from such data for autonomous driving. To address the needs found in this study, a key element of our language is to enable users to filter frame, and then switch to filtering by objects. We also find that Y was able to correctly understand and explain the purpose of the syntax without too much time or guesswork.

% anguage such that users can filter by frame, and then switches to filtering by objects.
% We asked him to prepare a query from Scenic to translate into an Apperception query.
% We can have 1-2 queries and would take around 5-10 minutes.
% We also will ask him to bring a Scenic query that is difficult to write in Apperception.
% Show him our new design and how it works.
% Give multiple queries in our new design
% Ask him to give a short description of each of the queries.


% \todo{focus on our syntax and data model that it is understandable}
% \todo{focus on the part where he suggests us to implement a syntax where users can filter by frame and then switch to filter by objects}

% \todo{What research questions drove the design of the study?}

% \todo{How did you collect data about your target population?}

% \todo{How did you find participants?}

% \todo{How did you select participants?}

% \todo{What procedure did you use for collecting data?}

% \todo{What materials, if any, did you show participants?}

% \todo{What data did you collect?}

% \todo{What did you learn from the user data?}

% \todo{How did you learn it?  What led you to these conclusions?  Be specific.}

% \todo{What quotes, stories, numbers, or patterns back up these conclusions or offer extra detail?}

% \todo{Which conclusions surprised you?}

% \todo{How did your conclusions from the user data affect what you did next?}

% \todo{How should your conclusions from the user data affect what future researchers do?}